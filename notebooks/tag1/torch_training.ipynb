{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "from torcheval.metrics.functional import multiclass_accuracy\n",
    "# We are using the titanic dataset to learn about torch and neural networks, not because it is particulary intresting or neural networks are suited for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data and transform into torch tensors.\n",
    "batch_size = 4\n",
    "feature_columns = [\"Sex\", \"Age\", \"Pclass\"]\n",
    "\n",
    "train_df = pl.read_parquet(\"train.parquet\")\n",
    "train_df = train_df.select(feature_columns + [\"Survived\"])\n",
    "train_dataset = train_df.to_torch(return_type=\"dataset\", label=\"Survived\", features=feature_columns)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "eval_df = pl.read_parquet(\"eval.parquet\")\n",
    "eval_df = eval_df.select(feature_columns + [\"Survived\"])\n",
    "eval_dataset = eval_df.to_torch(return_type=\"dataset\", label=\"Survived\", features=feature_columns)\n",
    "eval_loader = torch.utils.data.DataLoader(dataset=eval_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressor(torch.nn.Module):\n",
    "    def __init__(self, in_features: int):\n",
    "        super().__init__()\n",
    "        self.regressor = torch.nn.Linear(in_features=in_features, out_features=2)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.regressor(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "class BasicNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, in_features: int):\n",
    "        super().__init__()\n",
    "        self.neural_network = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features, 4),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4, 2),\n",
    "            torch.nn.Softmax(dim=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x =  self.neural_network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "model = LinearRegressor(in_features=3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "#Basic training loop\n",
    "for epoch in range(epochs):    \n",
    "    model.train() # activates training mode\n",
    "    for features, labels in train_loader:\n",
    "        optimizer.zero_grad() # zero gradients from previous step\n",
    "        preds = model(features) # Make prediciton based on features\n",
    "        loss = loss_fn(preds, labels) # calculates loss based on model prediciton and known truth (label)\n",
    "        loss.backward() # calculate gradients based on loss\n",
    "        optimizer.step() # Adjusts model parameters based on gradients\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the loss and the accuracy of the model for a given dataloader\n",
    "def evaluate(data_loader: torch.utils.data.DataLoader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        labels = []\n",
    "        for features, label in data_loader:\n",
    "            labels.append(label)\n",
    "            preds.append(model(features))\n",
    "        preds = torch.concat(preds)\n",
    "        labels = torch.concat(labels)\n",
    "        loss = loss_fn(preds, labels).item()\n",
    "        accuracy = multiclass_accuracy(preds, labels).item()\n",
    "        return {\"loss\": loss, \"acc\": accuracy}\n",
    "    \n",
    "# Example usage:\n",
    "results_train = evaluate(train_loader)\n",
    "print(results_train)\n",
    "results_eval = evaluate(eval_loader)\n",
    "print(results_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: \n",
    "# Evaluate on the train- and eval-Dataloader after every epoch.\n",
    "# Tip: you have to move the cell with \"evaluate\" before the training loop.\n",
    "# Tip: just copy and paste the example code after the second for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optinal Task 1.1 (python)\n",
    "# Report the metrics from Task 1 in a prettier way using f-Strings. Also include the epoch.\n",
    "# Example f-String:\n",
    "x = 2\n",
    "y = 3\n",
    "print(f\"{x} * {y} = {x*y}\")\n",
    "# You can also limit the number of digits after the decimal point:\n",
    "print(f\"{x} / {y} = {x/y:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: \n",
    "# Switch the model to the basic neural network and train again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Modify the function below to actually use the sex, age and pclass, not just zeros.\n",
    "# Would you have survived?\n",
    "def predict(sex: int, age: int, pclass: int):\n",
    "    model.eval()\n",
    "    features = torch.tensor([0, 0, 0], dtype=torch.float32)\n",
    "    print(features)\n",
    "    pred = model(features)\n",
    "    print(pred)\n",
    "\n",
    "predict(sex=0, age=35, pclass=3)\n",
    "\n",
    "# Optional Task 3.1 (torch, python):\n",
    "# make the output pretty and print whether the individual likely survived or died."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4:\n",
    "# Play around with the hyperparamters learning_rate, batch_size and epochs; also compare the linear regressor and neural network.\n",
    "# Tip: They are at the top of the cells\n",
    "# Try to improve the accuracy of the model!\n",
    "# Tip: Spend less than 15 minutes on this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5:\n",
    "# Add the \"Fare\" as a feature. (Fare = ticket price)\n",
    "# Tip: you have to increase the in_features of your model to allow for the additional input.\n",
    "# Is there a way to automatically adjust the in_features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6:\n",
    "# Increase the hidden size of the neural network.\n",
    "\n",
    "# Task 6.1:\n",
    "# If you haven't done so already: make the hidden size a parameter for the __init__, analog to in_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7:\n",
    "# Use AdamW instead of SGD as an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task: (torch, python)\n",
    "# Write a class for a deep neural network\n",
    "# Tip: A deep neural network contains at least 2 Hidden layers, one more than the BasicNeuralNetwork\n",
    "# Tip: Just copy the code from the Basic Neural network and add one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task: (torch, ml)\n",
    "# Look into what dropout is, example below\n",
    "# Add dropout to the model. Experiment with different probabilities.\n",
    "# Tip: Do not apply dropout on the inputs or the outputs, but after a linear layer.\n",
    "prob = 0.5\n",
    "dropout = torch.nn.Dropout(p=prob)\n",
    "tensor = torch.tensor([[0.0, 1.0, 2.0, 3.0, 4.0, 5.0]])\n",
    "for i in range(10):\n",
    "    print(dropout(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task: (python, torch)\n",
    "# Write a Neural Network class that takes a list of integers as an argumnet and constructs a corresponding neural network. \n",
    "# The first number is the number of inputs, the last the number of outputs and the other numbers the size of the hidden layers in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task (torch)\n",
    "# Calculate accuracy with torch directly, without multiclass_accuracy\n",
    "# Tip: use argmax\n",
    "# Ensure that your implementation scales to multiclass problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task: (polars, python, torch)\n",
    "# Tip: This is one of the harder tasks.\n",
    "# Try to include other features in your model, including string features.\n",
    "# Try to use one-hot-encoding for string features.\n",
    "# Tip: Modify the titanic notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task (torch)\n",
    "# Train a LinearRegressor and try to interpret the weights.\n",
    "# Can you do the same for the neural network or even the deep neural network?\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task (python, polars):\n",
    "# Find another Dataset with similarly structured/tabular data and train a model on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task (python and/or polars)\n",
    "# Do some data analysis on the training data and figure out what predicts whether a passanger survived.\n",
    "# Try to use polars as much as possible, and don't dare to use pandas.\n",
    "# Do your results corespond with the model paramteres of the LinearRegressor?\n",
    "\n",
    "# Optional Task (python)\n",
    "# Try to visualize your results (for example with pyplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task (ml, python)\n",
    "# Implement early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task (ml, torch)\n",
    "# Look into the parameters of AdamW and play around with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task (torch, ml)\n",
    "# Use a learning rate shedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task (torch)\n",
    "# clalculate other metrics than simple accuracy. E. g. precicsion, recall, balanced accuracy etc.\n",
    "# Use pytroch directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Task (torch)\n",
    "# Rewrite the notebook in such a way that the model only has one output, using sigmoid instead of softmax.\n",
    "# Tip: create a copy of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
